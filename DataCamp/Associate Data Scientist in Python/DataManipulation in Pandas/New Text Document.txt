# Print the head of the homelessness data
print(homelessness.head())

# Print information about homelessness
print(homelessness.info())

# Print the shape of homelessness
print(homelessness.shape)

# Print a description of homelessness
print(homelessness.describe())

--------------


# Import pandas using the alias pd
import pandas as pd
# Print the values of homelessness

print(homelessness.values)

# Print the column index of homelessness
print(homelessness.columns)

# Print the row index of homelessness
print(homelessness.index)
----------------
# Sort homelessness by individuals
homelessness_ind = homelessness.sort_values("individuals")

# Print the top few rows
print(homelessness_ind.head())
---------------
# Sort homelessness by region, then descending family members
homelessness_reg_fam = homelessness.sort_values(["region", "family_members"], ascending=[True, False])

print(homelessness_reg_fam.head())
----------
# Select the individuals column
individuals = homelessness["individuals"]

print(individuals.head())
-----------
# Select the state and family_members columns
state_fam = homelessness[["state", "family_members"]]

print(state_fam.head())
******************
# Select only the individuals and state columns, in that order
ind_state = homelessness[["individuals", "state"]]

print(ind_state.head())
-------------------
# Filter for rows where individuals is greater than 10000
ind_gt_10k = homelessness[homelessness["individuals"] > 10000]

# See the result
print(ind_gt_10k)
---------------
# Filter for rows where region is Mountain
mountain_reg = homelessness[homelessness["region"] == "Mountain"]

# See the result
print(mountain_reg)
--------------------
# Filter for rows where family_members is less than 1000 
# and region is Pacific
fam_lt_1k_pac = homelessness[(homelessness["family_members"] < 1000) & (homelessness["region"] == "Pacific")]

# See the result
print(fam_lt_1k_pac)
---------------------
# The Mojave Desert states
canu = ["California", "Arizona", "Nevada", "Utah"]

# Filter for rows in the Mojave Desert states
mojave_homelessness = homelessness[homelessness["state"].isin(canu)]

# See the result
print(mojave_homelessness)
-----------------------
# Print the head of the sales DataFrame
print(sales.head())

# Print the info about the sales DataFrame
print(sales.info())

# Print the mean of weekly_sales
print(sales["weekly_sales"].mean())

# Print the median of weekly_sales
print(sales["weekly_sales"].median())
-----------------
# Print the maximum of the date column
print(sales['date'].max())

# Print the minimum of the date column
print(sales['date'].min())
--------
# Print the head of the homelessness data
print(homelessness.head())

# Print information about homelessness
print(homelessness.info())

# Print the shape of homelessness
print(homelessness.shape)

# Print a description of homelessness
print(homelessness.describe())
----------
# Import pandas using the alias pd
import pandas as pd

# Print the values of homelessness

print(homelessness.values)

# Print the column index of homelessness
print(homelessness.columns)
# Print the row index of homelessness

print(homelessness.index)
-----------------
# Sort homelessness by descending family members
homelessness_fam = homelessness.sort_values("family_members", ascending=False)

# Print the top few rows
print(homelessness_fam.head())----------
-----------------------
# Sort homelessness by region, then descending family members
sortColums=['region','family_members']

homelessness_reg_fam = homelessness.sort_values(sortColums,ascending=[True,False])

# Print the top few rows
print(homelessness_reg_fam.head())
-----------------
# Select only the individuals and state columns, in that order
ind_state = homelessness[['individuals',"state"]]
print(ind_state.head())
print(homelessness)
-------------------------
# Filter for rows where individuals is greater than 10000
ind_gt_10k =homelessness[homelessness["individuals"]>10000] 

# See the result
print(ind_gt_10k)
--------
# Filter for rows where individuals is greater than 10000
ind_gt_10k =homelessness[homelessness["individuals"]>10000] 

# See the result
print(ind_gt_10k)
---------------------
# Filter for rows where region is Mountain


print(homelessness)
mountain_reg = homelessness[homelessness["region"]=="Mountain"]

# See the result
print(mountain_reg)
-------------
# Filter for rows where family_members is less than 1000 
# and region is Pacific
fam_lt_1k_pac = homelessness[(homelessness["family_members"] < 1000) & (homelessness["region"] == "Pacific")]

# See the result
print(fam_lt_1k_pac)



# See the result
print(fam_lt_1k_pac)

---------
# The Mojave Desert states
canu = ["California", "Arizona", "Nevada", "Utah"]

# Filter for rows in the Mojave Desert states
mojave_homelessness = homelessness[homelessness["state"].isin(canu)]

# See the result
print(mojave_homelessness)
--------------------
# Add total col as sum of individuals and family_members

homelessness["total"]=homelessness["individuals"]+homelessness["family_members"]
print(homelessness)


# Add p_homeless col as proportion of total homeless population to the state population
homelessness['p_homeless']=homelessness["total"]/homelessness["state_pop"]

# See the result
print(homelessness)
--------------------
To add a column, use syntax like df["new_col"] = df["col_a"] / df["col_b"].
To filter rows, use syntax like df[df["col"] > n].
To sort rows, use syntax like df.sort_values("col", ascending=False).
To select columns, use syntax like df[["col_a", "col_b"]]

-----------

# Create indiv_per_10k col as homeless individuals per 10k state pop
homelessness["indiv_per_10k"] = 10000 * homelessness["individuals"] / homelessness["state_pop"] 

# Subset rows for indiv_per_10k greater than 20
high_homelessness = homelessness[homelessness["indiv_per_10k"] > 20]

# Sort high_homelessness by descending indiv_per_10k
high_homelessness_srt = high_homelessness.sort_values("indiv_per_10k", ascending=False)

# From high_homelessness_srt, select the state and indiv_per_10k cols
result = high_homelessness_srt[["state", "indiv_per_10k"]]

# See the result
print(result)
---------------
# Print the head of the sales DataFrame
print(sales.head())

# Print the info about the sales DataFrame
print(sales.info())

# Print the mean of weekly_sales
print(sales["weekly_sales"].mean())

# Print the median of weekly_sales
print(sales["weekly_sales"].median())
------------------
# Print the maximum of the date column


print(sales['date'].max())
# Print the minimum of the date column
print(sales['date'].min())
---------------
# Create a custom IQR function
def iqr(column):
    return column.quantile(0.75) - column.quantile(0.25)

# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg([iqr, "median"]))
*---------------------

# Create a custom IQR function
def iqr(column):
    return column.quantile(0.75) - column.quantile(0.25)

# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg([iqr, "median"]))
--------------------------


# Sort sales_1_1 by date
sales_1_1 = sales_1_1.sort_values("date")

# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col
sales_1_1["cum_weekly_sales"] = sales_1_1["weekly_sales"].cumsum()

# Get the cumulative max of weekly_sales, add as cum_max_sales col
sales_1_1["cum_max_sales"] = sales_1_1["weekly_sales"].cummax()

# See the columns you calculated
print(sales_1_1[["date", "weekly_sales", "cum_weekly_sales", "cum_max_sales"]])
-------
# Drop duplicate store/type combinations
store_types = sales.drop_duplicates(subset=["store", "type"])
print(store_types.head())

# Drop duplicate store/department combinations
store_depts = sales.drop_duplicates(subset=["store", "department"])
print(store_depts.head())

# Subset the rows where is_holiday is True and drop duplicate dates
holiday_dates = sales[sales["is_holiday"]].drop_duplicates(subset="date")

# Print date col of holiday_dates
print(holiday_dates["date"])

------------------
Select the type column of store_types, then call .value_counts().
Select the department column of store_depts and call .value_counts().
To calculate proportions, set normalize to True in .value_counts().
To sort the counts, set sort to True.
----------------

Call .groupby(), passing "type", then select the weekly_sales column and call .sum()
You can use the sum() function on sales_by_type to get the total sales.
# Group by type; calc total weekly sales
sales_by_type = sales.groupby("type")["weekly_sales"].sum()

# Get proportion for each type
sales_propn_by_type = sales_by_type / sum(sales_by_type)
print(sales_propn_by_type)
# Group by type; calc total weekly sales
sales_by_type = sales.groupby("type")["weekly_sales"].sum()

# Get proportion for each type
sales_propn_by_type = sales_by_type / sum(sales_by_type)
print(sales_propn_by_type)
------------
# From previous step
sales_by_type = sales.groupby("type")["weekly_sales"].sum()

# Group by type and is_holiday; calc total weekly sales
print(sales)
sales_by_type_is_holiday = sales.groupby(['type','is_holiday'])['weekly_sales'].sum()
# print(sales_by_type_is_holiday)
-------------
# For each store type, aggregate weekly_sales: get min, max, mean, and median

sales_stats = sales.groupby("type")["weekly_sales"].agg(["min", "max", "mean", "median"])


# Print sales_stats
print(sales_stats)

# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median
unemp_fuel_stats = sales.groupby("type")[["unemployment", "fuel_price_usd_per_l"]].agg(["min", "max", "mean", "median"])
print(unemp_fuel_stats)

